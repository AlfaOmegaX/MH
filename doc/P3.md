---
title: "\\textbf{Práctica 3.b:} \\ Enfriamento Simulado, Búsqueda Local Reiterada y \\ Evolución Diferencial para el \\ para el Problema del Aprendizaje de Pesos en Características"
author: Miguel Lentisco Ballesteros
subtitle: Metaheurísticas
documentclass: scrbook
classoption: oneside
lang: es
algos: Genéticos, Meméticos
colorlinks: true
bibliography: assets/citas.bib
biblio-style: apalike
link-citations: true
citation-style: assets/estilo.csl
numbersections: true
toc: true
---
## Búsqueda Local (BL)
El uso de BL para distintos algoritmos merece una explicación en este apartado, como algoritmo usado por otros, el armazón general es:

```haskell
busLoc :: StdGen -> Algoritmo
busLoc gen datos = getPesos solRes
  where solRes = evalua hastaQueM (nIter >= 15000 || nVecinos >= 20 * nCaract datos)
    (crearVecino datos) (pesosIniBL datos)) (gen, 0)
```
Donde obviamente cada algoritmo cambiará las condiciones según necesite (ej en vez de 15k, 1k evaluaciones; o sin parada por generación máxima de vecinos), en nuestro caso general hasta 15k iteraciones o cuando el nº de vecinos generados sin cambiar la solución sea 20 * nº características.

La solución inicial, con los índices posibles a mutar (inicialmente todos):
```haskell
pesosIniBL :: Datos -> Estado (Solucion, [Int])
pesosIniBL datos = return (pesosIniRand datos, [0..(nCaract datos - 1)])
```

Y cada iteración creamos un vecino, de manera que si es mejor lo sustituimos y creamos todos los índices posibles a mutar enteros; si no es mejor se devuelve la solución actual sin el índice que ha mutado, y si se ha quedado sin índices que mutar se refrescan todos.
```haskell
-- Creo un nuevo vecino a partir de una solución
crearVecino :: Datos -> (Solucion, [Int]) -> Estado (Solucion, [Int])
crearVecino datos (sol, indices) = do
  let (solNueva, indNuev) = obtenerVecino 0.3 datos indices sol
  let solAct = aumentaVecino sol
  let indNuev' = if solNueva > solAct || null indNuev then [0..(nCaract datos - 1)] else indNuev
  return (max solNueva solAct, indNuev')
```

Finalmente la obtención de un vecino es aplicar el operador de mutación en un índice aleatorio (modificar con un valor normal con desviación típica 0.3 y media 0.0), devolviendo la nueva solución y quitando el índice que se ha modificado de la lista de índices disponibles.
```haskell
obtenerVecino :: Datos -> [Int] -> Solucion -> Estado (Solucion, [Int])
obtenerVecino datos indices sol = do
  let inds = aleatorio (0, length indices - 1)
  let ind = indices !! inds
  let z = rNormal 0.3 0.0
  let pesosN = U.imap (\i x -> if i == ind then restringe $ x + z else x) $ getPesos sol
  return (crearSolucion datos pesosN, delete ind indices)
```

# Algoritmos de búsqueda

## Enfriamento Simulado (ES)
Este algoritmo basado en trayectorias (en concreto permite empeoramientos de la solución actual), es muy similar a la búsqueda local pero añade más diversidad (exploración) a la búsqueda permitiendo tomar vecinos peores. Basado en el recocido del acero, añade una probabilidad de tomar vecinos peores basada en la temperatura (cuanto más alta más probabilidad de aceptar), que empieza siendo muy alta para ir variando en la búsqueda y en cada iteración va enfriandose hasta llegar a la temperatura final, donde se va aceptando menos y menos vecinos (se incrementa la explotación).

De tipos simplemente he hecho un renombre para que sea mas legible, `Temp` es un `Double` y hace referencia a un dato que sea una temperatura.

El esqueleto general sería:
```haskell
eS :: StdGen -> Algoritmo
eS gen datos = getPesos solMej
  where solMej = evaluar (hastaQue (nIter >= 15000 || nExitos == 0)
    (iterEnfriamento datos) (solIniES 0.3 0.3 datos)) (gen, 0)
```

Creamos la sol inicial:
```haskell
-- Crea la solución inicial que consta de: SolAct + + TActual + MejorSol + T0 + Tf
solIniES :: Double -> Temp -> Datos -> Estado (Solucion, Temp, Solucion, Temp, Temp, Int)
solIniES mu phi datos = do
  let solIni = hastaQue (getFit solIni > - log phi * mu * 0.001) (pesosIniRand datos)
  let tempIni = mu * getFit solIni / (- log phi)
  return (solIni, tempIni, solIni, tempIni, 0.001, 1)
```
Considerando que la temperatura inicial es, con $\mu = \phi = 0.3$:

$$T_0 = \frac{\mu f(S_0)}{-ln(\phi)}$$

Creamos varias soluciones iniciales hasta que una de ellas tenga una temperatura inicial válida (que sea mayor que la final, $f(sol) > -0.001 log(\phi)\mu$), y ponemos la temp final a 0.001. La estructura que deuelve sirve para llevar la siguiente información: (solucionActual, temperaturaActual, mejorSolucion, T0, TF, nExitos). T0, TF serán constantes para usarlas al enfriar la temperatura, nExitos marcará el nº de vecinos aceptados en cada iteración (para comprobar si nExitos == 0 y cortar), mejorSolucion será la mejor solución encontrada durante toda la ejecución, y solucionActual y temperaturaActual la solución y temperatura actual en cada iteración.

Cada iteración del bucle será:
```haskell
-- Iteración principal se hace la busqueda en el vecindario y se enfria la temperatura
iterEnfriamento :: Datos -> (Solucion, Temp, Solucion, Temp, Temp, Int) -> Estado (Solucion, Temp, Solucion, Temp, Temp, Int)
iterEnfriamento datos (solAct, tAct, mejSol, t0, tf, _) = do
  let nMaxVec = nCaract datos * 10
  let (solNueva, solMejNueva, nVecExi)
    = hastaQueM (nIter >= 15000 || nVec >= nVecMax || nVecExi >= (nVecMax * 0.1))
    (exploraVecindario datos tAct) (solAct, mejSol, 0, 0)
  let m = redondea (15000 / nMaxVec)
  return (solNueva, enfriaCauchy m tAct t0 tf, solMejNueva, t0, tf, nVecExi)
```
Tomamos el nº máximo de vecinos a generar `nMaxVec` como nº de características por 10, a continuación exploramos el vecindario hasta que lleguemos a las 15k iteraciones, o el nº de vecinos generados llegue al tope, o se hayan aceptado el nº máxito de éxitos; entonces nos devuelve la nueva solución (puede ser la misma que la actual), la mejor solución (puede ser la misma que la actual) y el nº de vecinos aceptados, pasamos toda esta información para la siguiente iteración si procede, enfriando además la temperatura mediante el esquema Cauchy-Mejorado tomando en cuenta que habrá `15000/nMaxVec` iteraciones aproximadamente:

```haskell
enfriaCauchy :: Int -> Temp -> Temp -> Temp -> Temp
enfriaCauchy m t t0 tf = t / (1 + beta * t)
  where beta = (t0 - tf) / (m * t0 * tf)
```

El esquema es:

$$T_{k+1} = \frac{T_k}{1 + \beta T_k}, \; \; \beta = \frac{T_0 - T_F}{M T_0 T_F}$$

Finalmente, la exploración del vecindario se hace de la siguiente manera:

```haskell
exploraVecindario :: Datos -> Temp -> (Solucion, Solucion, Int, Int) -> Estado (Solucion, Solucion, Int, Int)
exploraVecindario datos tAct (solAct, mejSol, nVec, nVecExi) = do
  let solNueva = obtenerVecino 0.3 datos solAct
  let diferencia = getFit solAct - getFit solNueva
  if diferencia == 0
    diferencia = 0.005
  let numR = aleatorio (0.0, 1.0)
  if diferencia' < 0 || numR <= exp (- diferencia / tAct) then
    return (solNueva, max solNueva mejSol, nVec + 1, nVecExi + 1)
  else
    return (solAct, mejSol, nVec + 1, nVecExi)
```

Generamos un nuevo vecino y obtenemos la diferencia de evaluación de la sol actual menos la nueva, si la diferencia es 0 (que suele pasar) le ponemos 0.005 para que no se acepte siempre incluso con temperaturas bajas. Entonces generamos un nº aleatorio y si la diferencia es negativa (el vecino es mejor) o $rand \leq exp(-\frac{-diferencia}{T_{act}})$ entonces aceptamos el vecino como solución actual, comprobamos si es mejor que la mejor solución actual y aumentamos el nº de vecinos aceptados; en caso contrario no hacemos nada. En cualquier caso aumentamos en 1 el nº de vecinos creados.

Finalmente para crear un vecino, aplicamos el mismo operador de mutación de BL:
```haskell
obtenerVecino :: Datos -> Solucion -> Estado Solucion
obtenerVecino sD datos sol = do
  let ind = aleatorio (0, nCaract datos - 1)
  let z = rNormal 0.3 0.0
  let pesosN = imap (\i x -> if i == ind then restringe $ x + z else x) $ getPesos sol
  return crearSolucion datos pesosN
```

## Búsqueda Local Reiterada (ILS)
Este algoritmo basado en trayectorias, subtipo multiarranque, se basa en arrancar muchas veces la búqsueda local de la siguiente manera: tomamos una solución inicial y le aplicamos búsqueda local, después aplicamos un bucle que consiste en mutar la solución actual, aplicarle la búsqueda local y quedarnos con la mejor de la soluciones y volver a repetir.

Como usaremos BL llamamos al esqueleto de BL modificado solo para que pare al hacer 1000 evaluaciones (no se decía nada sobre si parar al generar nMaxVecinos asi que he decidido hacer 1k iteraciones solamente), y sigue el mismo esquema que el explicado en las consideraciones generales.

El esquema general sería:
```haskell
iLS :: StdGen -> Algoritmo
iLS gen datos = getPesos sol
  where sol = evalua (hastaQue (nIter >= 15) (iteracionILS datos) (solIniILS datos)) (gen, 0)
```
Considerando que haremos 15 iteraciones (contando con la solución inicial) a BL tendremos 15000 evaluaciones (igual que en otros algoritmos).

La solución inicial es la misma pero aplicando BL, y llevando la cuenta del nº de iteraciones:
```haskell
solIniILS :: Datos -> Estado (Solucion, Int)
solIniILS datos = return (bL datos (pesosIniRand datos), 1)
```

Cada iteración de ILS será así:
```haskell
iteracionILS :: Datos -> (Solucion, Int) -> Estado (Solucion, Int)
iteracionILS datos (solAct, nIter) = do
  let solMutada = mutarSolILS datos solAct
  let solBL = blILS datos solMutada
  return (max solAct solBL, nIter + 1)
```

Tomamos la sol actual, le aplicamos la operación de mutación, y después BL. Finalmente devolvemos la mejor solución para seguir aplicando el algoritmo y aumentamos en 1 el nº de iteraciones. Como considerabamos el criterio de elección como el mejor no hace falta llevar la cuenta de la mejor solución, en cualquier caso se podría hacer una pequeña modificación si se quisiera cambiar el criterio.

La mutación de la solución:
```haskell
mutarSolILS :: Datos -> Solucion -> Estado Solucion
mutarSolILS datos solAct = do
  let nMut = min 1 $ redondea $ 0.1 * (nCaract datos)
  let pesosMutados = repiteNM nMut (mutarPesos 0.4) (getPesos solAct)
  return crearSolucion datos pesosMutados
```
Esta mutación es parecida a la de siempre pero más agresiva, en este caso usamos desviación tipica 0.4 en vez de 0.3 y además mutamos el 10% de los genes (y ponemos un mínimo de mutación de 1 gen para q mute al menos una vez) usando el operador normal de siempre aplicado `nMut` veces.

## Evolución Diferencial (DE)
Este algoritmo basado en algoritmos genéticos, hace más énfasis en la mutación, que va antes de la recombinación/cruce. El esquema general es generar una población inicial de N cromosomas y hasta que se cumpla la condición de parada seguir el siguiente bucle: para todo individuo de la población se genera un hijo nuevo tomando de base los pesos del padre (individuo i) y de manera que por cada gen del nuevo hijo hay una probabilidad de se aplique el operador de mutación; en cualquier caso cuando se forma el nuevo hijo entero si es mejor que el padre se reemplaza.

Como las dos variantes serán usando un operador de cruce distinto, explicaré en general todo y después veremos las dos fórmulas diferentes usadas en los dos algoritmos. De esta manera el operador de cruce (rand o best-current) está unido al de recombinación (binominal), y después de aplicarse a todos los genes del hijo se aplica el de reemplazo (compara hijo-padre)

Se ha incluido el tipo `EsqMutar` que hace referencia al esquema de mutar que es el siguiente `type EsqMutar = Poblacion -> Int -> Int -> [Int] -> Estado Double`. Tomará la población, los índices i y j (i sobre la población y j sobre el nº)

Empezamos con el esquema general, donde variará segun el esquema de mutación que usemos:
```haskell
dE :: EsqMutar -> StdGen -> Algoritmo
dE esqMut gen datos = getPesos (maximo pobSol)
  where pobSol = evaluar (hastaQue (nIter >= 15000) (iterDE datos esqMut) (crearPobIni 50 datos)) (gen, 0)
```

La población inicial se crea repitiendo n veces creando cromosomas con pesos aleatorios:
```haskell
-- Crea nPob individuos aleatorios
crearPobIni :: Int -> Datos -> Estado Poblacion
crearPobIni nPob datos = repite nPob (crearCromIni datos)
```

Cada iteración del bucle será aplicar la misma operación a cada cromosoma de la población, actualizando la población, y empezando con i = 0:
```haskell
iterDE :: Datos -> EsqMutar -> Poblacion -> Estado Poblacion
iterDE datos esqMutRecom pobActual = repite (sizeOf pobActual) (actualizarPoblacion datos esqMutRecom) (pobActual, 0)
```

Por cada cromosoma generamos unos pesos inicialmente a 9 (da igual) y tomamos 3 índices distintos entre sí y de i que se los pasaremos al esquema de mutación según los necesiten. Al aplicar el bucle interno obtendremos los pesos del nuevo hijo, creando el nuevo cromosoma hijo y finalmente si el hijo es mejor que el padre se sustituye por él en la población (reemplazo) y devolvemos la población actualizada:

```haskell
actualizarPoblacion :: Datos -> EsqMutar -> (Poblacion, Int) -> Estado (Poblacion, Int)
actualizarPoblacion datos esqMut (pob, i) = do
  let vectorIni = replica (nCaract datos) 0
  let indices = tomaIndRand 3 (delete i [0..(sizeOf pob - 1)])
  let hijoNuevo = crearCromosoma datos $ repiteNM (nCaract datos) (mutReemp esqMut pob i indices) (vectorIni, 0)
  if getFit hijoNuevo > getFit pob[i] then pob[i] = hijoNuevo
  return (pob, i + 1)
```

Es muy fácil tomar índices distintos tomando una posición de la lista de índices y repitiendo quitando ese índice de la lista y así:
```haskell
tomaIndRand :: Int -> [Int] -> Estado [Int]
tomaIndRand nInd indices = repite nInd tomaIndice (indices, [])
  where tomaIndice (inds, res) = do
        let k =  (0, sizeOf inds - 1)
        return (delete inds[i] inds, res ++ inds[i])
```

Por último el esquema de mutación/combinación:
```haskell
mutReemp :: EsqMutar -> Poblacion -> Int -> [Int] -> ([Double], Int) -> Estado ([Double], Int)
mutReemp esqMut pob i indices (pesos, j) = do
  let r = aleatorio (0.0, 1.0)
  if r <= (0.5 :: Double) then pesos[j] = esqMut pob i j indices else pesos[j] = pob[i].pesos[k]
  return (pesos, j + 1)
```
Tomamos un nº aleatorio en $[0.0, 1.0]$ y si es menor que CR, que en este caso es 0.5 entonces se el valor del gen j-ésimo valdrá lo que nos dia el operador de mutación; si no se toma lo que valga el gen j-ésimo del padre. Como CR vale 0.5 y por tanto se espera una mutación del 50% de los genes, y no se indicaba nada en el esquema general he decidido no hacer la condición $j = j_{rand}$ ya que sería asegurar la mutación de al menos un gen y estaría bien para casos con CR bajo pero en este caso añadir una mutación mas o menos no lo veo necesario.

### DE - Rand
El esquema es aleatorio, se toma como mutación 3 padres aleatorios (distintos entre sí y del individuo i-ésimo) y se toma una suma de ellos de una forma (y se restringe al intervalo $[0.0, 1.0]$):
```haskell
mutRand :: EsqMutar
mutRand pob _ j (i1, i2, i3) = return $ restringe $ pob[i1].pesos[j] + 0.5 * (pob[i2].pesos[j] - pob[i3].pesos[j])
```

Por tanto:
```haskell
dERand :: StdGen -> Algoritmo
dERand = dE mutRand
```

Obviamente en este caso no se tiene en cuenta al padre i-ésimo y además es una combinación aleatoria pura sin tener en cuenta nada.

### DE - Best Current
El esquema toma en consideración el padre i-ésimo, el mejor individuo de la población y dos padres aleatorios (distintos entre sí y del padre i-ésimo), además se restringe el valor al intervalo $[0.0, 1.0]$:
```haskell
mutCurrentBest :: EsqMutar
mutCurrentBest pob i j i1 i2 = do
  let iMejor = maximum pob `indiceDe` pob
  return $ restringe $ pob[i].pesos[j] + 0.5 * (pob[iMejor].pesos[j]  - pob[i].pesos[j] ) + 0.5 * (pob[i1].pesos[j] - pob[i2].pesos[j])
```

Por tanto:
```haskell
dECurrentBest :: StdGen -> Algoritmo
dECurrentBest = dE mutCurrentBest
```

En este caso se tiene en cuenta más quien es el mejor y tira hacia él (explotación) añadiendo también un poco de exploración con los padres aleatorios pero teniendo en cuenta la base de la que parte (el padre i-ésimo).


# Casos de comparación

## P1
Se nos pide que comparemos estos algoritmos con los originales 1-NN (PESOS UNO) y RELIEF, como 1-NN simplemente es poner todos los pesos a 1.0, volvemos a explicar RELIEF solo.

### RELIEF
Este algoritmo basado en técnica greedy es muy sencillo, empezamos inicializando el vector de pesos W a cero y usando el conjunto de entrenamiento, por cada punto de este actualizamos los pesos coordenada a coordenada de la siguiente manera: buscamos el punto más cercano de la misma clase (amigo) y le restamos la distancia 1 coordenada a coordenada, igual buscamos el punto más cercano que no sea de su clase y sumamos la distancia 1 coordenada a coordenada.

Finalmente truncamos a 0 los valores de los pesos negativos, y después normalizamos todos los valores en el intervalo $[0,1]$.

La función principal:

```haskell
relief :: Algoritmo
relief dEntrenamiento =
  let wCero        = repite (nCaract dEntrenamiento) 0.0
      wRes         = acumula (\w p -> actualizaPesos p trainData w) wCero dEntrenamiento
      wPos         = map (\w -> if w < 0.0 then 0.0 else w)
      (wMax, wMin) = (max wPos, min wPos)
  in map (normaliza w pMax pMin) wRes
```
La idea es simple, creamos los `pesosCero` que son los iniciales (de tamaño n), aplicamos para cada punto la función que lo actualiza y vamos realizándolo con cada punto hasta terminar. Finalmente normalizamos, trucando primero a 0 los valores negativos, sacando el máx y mín después y normalizando a $[0, 1]$.

La función para ir actualizando los pesos es:

```haskell
actualizaPesos :: Dato -> Datos -> Pesos -> Pesos
actualizaPesos p dEntrenamiento pAcumulados =
  let dist             = ordena $ map (\x -> dist1 p x) (quita p dEntrenamiento)
      amigo            = buscar (\x -> claseDe x == claseDe p) dist
      enemigo          = buscar (\x-> claseDe x != claseDe p) dist
      sumaPeso p e a w = p' `dist1c` e - p' `dist1c` a + w
  in juntarCon4 sumaPeso (valoresDe p) enemigo amigo pAcumulados
```
Simplemente tomando un punto fijo, sacamos la distancia de ese punto a todos del conjunto de entrenamiento y luego lo ordenamos; como queremos sacar el aliado hemos sacado de las distancias el propino punto `p` y ahora buscamos el primero que aparezca en la lista con la misma clase que p, igual que con los enemigos solo que buscamos el primero que tenga distinta clase. Finalmente aplicamos coordenada a coordenada aplicando los pesos acumulados (de ir aplicando a los cada punto) junto a la suma de la distancia enemiga y resta distancia amiga.

Las distancia 1 y distancia 1 coordenada a coordenada son:
```haskell
dist1 :: Dato -> Dato -> Float
dist1 p1 p2 = suma $ juntaCon dist1c p1 p2
```
``` haskell
dist1c :: Float -> Float -> Float
dist1c x y = abs (y - x)
```

## P2

### DE-Best
He añado una variante de DE, DE-Best, que el operador de mutación es el Best-1, implementado es:

```haskell
-- Mutación mejor: diferencia entre 2 aleatorios y suma el mejor
mutBest :: EsqMutar
mutBest pob _ j (i1:i2:_) = do
  let (iMejor:_) = maximo pob `indiceDe` pob
  return $ restringe $ pob[iMejor].pesos[j] + 0.5 * (pob[i1].pesos[j] - pob[i2].pesos[j])
```

Y por tanto:

```haskell
dEBest :: StdGen -> Algoritmo
dEBest = dE mutBest
```

# Procedimiento considerado para desarrollar la práctica.
Todo el código está implementado en Haskell, sin usar ningún framework. El código está en la carpeta `FUENTES`. Para compilar he dejado un archivo make en `BIN` de manera que para instalar el compilador y sus dependencias solo hay que instalar `stack` aquí se puede consultar como instalarlo [stack](https://docs.haskellstack.org/en/stable/README/). Para compilar el archivo solo hay que hacer `make build`, aunque la primera vez tardará porque tiene que descargar el compilador de Haskell y las dependencias. Una vez terminado se puede ejecutar `make run` para ejecutarlo sin argumentos.

Los distintos modos de ejecución serían:

- Sin argumentos: entonces se leen los 3 dataset que se encuentran en `BIN` y se ejecutan con una seed aleatoria.
- Un argumento: se pasa como argumento el nombre del fichero que se quiere leer y se ejecuta con una seed aleatoria.
- Dos argumentos: se pasa como argumento el nombre del fichero que se quiere leer y el nº de seed, se ejecuta el archivo con la seed que se ha pasado.

Que se resume en `./P3bin [nombreFichero] [seed]`.

He comprobado que la compilación y ejecución es satisfactoria en Fedora 28.

# Experimentos y análisis de resultados

## Descripción de los casos del problema
Todos los dataset se han leído en formato `.arff` y como se explicó al principio elimino datos repetidos. Todas las características son reales.

### Colposcopy
Colposcopy es un conjunto de datos de colposcopias anotado por médicos del Hospital Universitario de Caracas. El fichero tiene 287 ejemplos (imágenes) con 62 características (con distintos datos como valores medios/desviación estándar del color de distintos puntos de la imagen) de que deben ser clasificados en 2 clases (buena o mala).

Sin elementos repetidos seguimos teniendo 287 ejemplos efectivos; 71 elementos de la clase "0" y 216 elementos de la clase "1" habiendo un claro desequilibrio de clases.

### Ionosphere
Ionosphere es un conjunto de datos de radar recogidos por un sistema en Goose Bay, Labrador. Se intentan medir electrones libres en la ionosfera y se clasifican en 2 clases (bad o good). Se cuenta con 354 ejemplos y 34 características (representan valores de las señales electromagnéticas emitidas por los electrones) cada dato.

Con 4 elementos repetidos nos quedan 350 ejemplos efectivos, quedando en 125 elementos de la clase "b" y 225 elementos de la clase "g" donde no hay equilibrio de clases.

### Texture
Texture es un conjunto de datos de extración de imagénes para distinguir entre las 11 texturas diferentes (césped, piel de becerro prensada, papel hecho a mano...). Se tienen 550 ejemplos con 40 características que hay que clasificar en 11 clases.

Hay un elemento repetido que nos deja en 549 ejemplos donde todas las clases tienen 50 ejemplos excepto la clase "12" que tiene 49. Este conjunto de datos está equilibrado.

## Resultados obtenidos

Siguiendo el formato indicado, incluyo aquí una tabla por cada algoritmo recogiendo los resultados de cada algoritmo sobre cada dataset; y una tabla global recogiendo los resultados medios y desviación típica para cada dataset y cada algoritmo. Las particiones son las mismas para cada algoritmo y los valores están redondeados a las 2 decimales más significativos.

La descripción de la tabla es:

- Nº : nº partición
- Clas: tasa de clasificación (%)
- Red: tasa de reducción (%)
- Agr: función agregada
- T: tiempo que ha tardado el algoritmo en calcular los pesos (s)

Los datos resultantes se han generado con el generador de nº aleatorios "225938972 1", ejecutados en un ordenador con SO Fedora 28, IntelCore i5-7300HQ CPU @ 2.50GHz x 4.

### Algoritmos P1 (Aleatorios, 1NN, RELIEF, BL)

Resultados de la P1.

Tabla para los pesos todo uno (1NN normal) \ref{1nn}

Tabla para RELIEF \ref{relief}

\begin{table}[htbp]
\caption{Resultados obtenidos por el algoritmo 1NN (pesos uno) en el problema del APC}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
  &	\multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} & \multicolumn{4}{c}{\textsc{Texture}} \\
\textbf{Nº} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} \\ \hline
1 & 74.14 & 0.00 & 37.07 & 0.00 & 84.29 & 0.00 & 42.14 & 0.00 & 90.00 & 0.00 & 45.00 & 0.00 \\
2 & 81.03 & 0.00 & 40.51 & 0.00 & 85.71 & 0.00 & 42.86 & 0.00 & 91.82 & 0.00 & 45.90 & 0.00 \\
3 & 82.46 & 0.00 & 41.23 & 0.00 & 92.86 & 0.00 & 46.43 & 0.00 & 95.46 & 0.00 & 47.73 & 0.00 \\
4 & 68.42 & 0.00 & 34.21 & 0.00 & 84.29 & 0.00 & 42.14 & 0.00 & 90.00 & 0.00 & 45.00 & 0.00 \\
5 & 78.95 & 0.00 & 39.47 & 0.00 & 90.00 & 0.00 & 45.00 & 0.00 & 94.50 & 0.00 & 47.25 & 0.00 \\ \hline
$\bar{x}$ & 77.00 & 0.00 & 38.50 & 0.00 & 87.43 & 0.00 & 43.71 & 0.00 & 92.36 & 0.00 & 46.18 & 0.00 \\
$\sigma$ & 5.13 & 0.00 & 2.56 & 0.00 & 3.43 & 0.00 & 1.72 & 0.00 & 2.26 & 0.00 & 1.13 & 0.00
\end{tabular}
\end{center}
\label{1nn}
\end{table}

\begin{table}[htbp]
\caption{Resultados obtenidos por el algoritmo RELIEF en el problema del APC}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
  &	\multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} & \multicolumn{4}{c}{\textsc{Texture}} \\
\textbf{Nº} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} \\ \hline
1 & 79.31 & 25.80 & 52.56 & 0.01 & 81.43 & 2.94 & 42.19 & 0.01 & 96.36 & 37.50 & 66.93 & 0.03 \\
2 & 77.59 & 59.67 & 68.63 & 0.01 & 87.14 & 2.94 & 45.04 & 0.01 & 95.45 & 47.50 & 71.48 & 0.03 \\
3 & 84.21 & 30.65 & 57.43 & 0.01 & 91.43 & 2.94 & 47.19 & 0.01 & 97.27 & 45.00 & 71.14 & 0.03 \\
4 & 70.18 & 24.19 & 47.19 & 0.01 & 84.29 & 2.94 & 43.61 & 0.01 & 91.82 & 42.50 & 68.17 & 0.03 \\
5 & 87.72 & 27.42 & 57.57 & 0.01 & 90.00 & 5.88 & 47.94 & 0.01 & 96.33 & 40.00 & 68.16 & 0.03 \\ \hline
$\bar{x}$ & 79.80 & 33.55 & 56.67 & 0.01 & 86.86 & 3.53 & 45.19 & 0.01 & 95.45 & 42.50 & 68.97 & 0.03 \\
$\sigma$ & 6.00 & 13.24 & 7.00 & 0.00 & 3.66 & 1.18 & 2.15 & 0.0 & 1.90 & 3.54 & 1.80 & 0.00
\end{tabular}
\end{center}
\label{relief}
\end{table}

\newpage

### Algoritmos P3 (ES, ILS, DE)

Resultados de la P3.

Tabla para ES \ref{es}

Tabla para ILS \ref{ils}

Tabla para DE-Rand \ref{derand}

Tabla para DE-BestToCurrent \ref{decurrentbest}

Tabla para DE-Best \ref{debest}

\begin{table}[htbp]
\caption{Resultados obtenidos por el algoritmo ES en el problema del APC}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
  &	\multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} & \multicolumn{4}{c}{\textsc{Texture}} \\
\textbf{Nº} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} \\ \hline
1 & 74.14 & 83.87 & 79.01 & 116.51 & 87.14 & 91.18 & 89.16 & 81.27 & 90.00 & 85.00 & 87.50 & 221.00
2 & 70.69 & 80.65 & 75.67 & 115.13 & 84.29 & 88.24 & 86.26 & 69.66 & 90.91 & 85.00 & 87.96 & 219.29
3 & 73.68 & 79.03 & 76.36 & 86.58 & 85.71 & 91.18 & 88.45 & 61.83 & 88.18 & 80.00 & 84.09 & 222.18
4 & 80.70 & 77.42 & 79.06 & 116.56 & 84.29 & 88.24 & 86.26 & 81.24 & 89.09 & 82.50 & 85.80 & 228.49
5 & 77.19 & 87.10 & 82.15 & 115.56 & 85.71 & 91.18 & 88.45 & 62.32 & 89.00 & 85.00 & 87.00 & 230.29
$\bar{x}$ & 75.28 & 81.61 & 78.45 & 110.07 & 85.43 & 90.00 & 87.71 & 71.26 & 89.43 & 83.50 & 86.47 & 224.25
$\sigma$ & 3.40 & 3.48 & 2.41 & 15.94 & & 1.07 & 1.44 & 1.22 & 8.62 & 0.94 & 2.00 & 1.39 & 4.33
\end{tabular}
\end{center}
\label{es}
\end{table}

\begin{table}[htbp]
\caption{Resultados obtenidos por el algoritmo ILS en el problema del APC}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
  &	\multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} & \multicolumn{4}{c}{\textsc{Texture}} \\
\textbf{Nº} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} \\ \hline
1 & 70.69 & 87.10 & 78.89 & 116.44 & 81.43 & 94.12 & 87.77 & 112.62 & 90.91 & 82.50 & 86.71 & 310.85
2 & 70.69 & 85.48 & 78.09 & 116.02 & 78.57 & 91.18 & 84.87 & 111.70 & 91.82 & 87.50 & 89.66 & 310.46
3 & 68.42 & 85.48 & 76.95 & 116.01 & 81.43 & 91.18 & 86.30 & 110.86 & 83.64 & 87.50 & 85.57 & 306.36
4 & 75.44 & 90.32 & 82.88 & 116.13 & 90.00 & 91.18 & 90.59 & 111.10 & 90.91 & 85.00 & 87.96 & 307.40
5 & 75.44 & 83.87 & 79.66 & 117.20 & 90.00 & 91.18 & 90.59 & 111.71 & 91.74 & 85.00 & 88.37 & 313.53
$\bar{x}$ & 72.14 & 86.45 & 79.29 & 116.36 & 84.29 & 91.77 & 88.03 & 111.60 & 89.80 & 85.50 & 87.65 & 309.72
$\sigma$ & 2.82 & 2.19 & 2.01 & 0.45 & 4.78 & 1.18 & 2.29 & 0.61 & 3.11 & 1.87 & 1.40 & 2.60
\end{tabular}
\end{center}
\label{ils}
\end{table}

\begin{table}[htbp]
\caption{Resultados obtenidos por el algoritmo DE-Rand en el problema del APC}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
  &	\multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} & \multicolumn{4}{c}{\textsc{Texture}} \\
\textbf{Nº} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} \\ \hline
1 & 62.07 & 93.55 & 77.81 & 121.92 & 87.14 & 91.18 & 89.16 & 115.27 & 90.00 & 87.50 & 88.75 & 303.98
2 & 72.41 & 93.55 & 82.98 & 121.14 & 88.57 & 91.18 & 89.87 & 113.49 & 91.82 & 87.50 & 89.66 & 318.04
3 & 71.93 & 90.32 & 81.13 & 128.13 & 91.43 & 91.18 & 91.30 & 117.88 & 88.18 & 87.50 & 87.84 & 311.89
4 & 75.44 & 95.16 & 85.30 & 131.28 & 84.29 & 94.12 & 89.20 & 123.22 & 92.73 & 87.50 & 90.11 & 316.17
5 & 73.68 & 91.94 & 82.81 & 128.51 & 85.71 & 91.18 & 88.45 & 122.27 & 92.66 & 87.50 & 90.08 & 319.49
$\bar{x}$ & 71.11 & 92.90 & 82.00 & 126.20 & 87.43 & 91.77 & 89.60 & 118.43 & 91.08 & 87.50 & 89.29 & 313.92
$\sigma$ & 4.68 & 1.65 & 2.49 & 3.87 & 2.46 & 1.18 & 1.70 & 3.49 & 1.75 & 0.00 & 0.88 & 5.59
\end{tabular}
\end{center}
\label{derand}
\end{table}

\begin{table}[htbp]
\caption{Resultados obtenidos por el algoritmo DE-BestToCurrent en el problema del APC}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
  &	\multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} & \multicolumn{4}{c}{\textsc{Texture}} \\
\textbf{Nº} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} \\ \hline
1 & 81.03 & 79.03 & 80.03 & 125.01 & 91.43 & 88.24 & 89.83 & 117.63 & 91.82 & 85.00 & 88.41 & 318.98
2 & 67.24 & 67.74 & 67.49 & 127.95 & 84.29 & 79.41 & 81.85 & 121.93 & 90.91 & 80.00 & 85.46 & 314.67
3 & 75.44 & 74.19 & 74.82 & 126.60 & 90.00 & 88.24 & 89.12 & 117.86 & 89.09 & 85.00 & 87.05 & 317.25
4 & 78.95 & 64.52 & 71.73 & 127.48 & 81.43 & 88.24 & 84.83 & 120.58 & 92.73 & 80.00 & 86.36 & 323.57
5 & 68.42 & 70.97 & 69.70 & 127.09 & 80.00 & 79.41 & 79.71 & 117.01 & 92.66 & 85.00 & 88.83 & 315.34
$\bar{x}$ & 74.22 & 71.29 & 72.75 & 126.83 & 85.43 & 84.71 & 85.07 & 119.00 & 91.44 & 83.00 & 87.22 & 317.96
$\sigma$ & 5.52 & 5.04 & 4.37 & 1.01 & 4.55 & 4.33 & 3.96 & 3.96 & 1.91 & 1.36 & 2.45 & 1.26 & 3.18
\end{tabular}
\end{center}
\label{decurrentbest}
\end{table}

\begin{table}[htbp]
\caption{Resultados obtenidos por el algoritmo DE-Best en el problema del APC}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
  &	\multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} & \multicolumn{4}{c}{\textsc{Texture}} \\
\textbf{Nº} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} & \textbf{Clas} & \textbf{Red} & \textbf{Agr} & \textbf{T} \\ \hline
$\bar{x}$ &
$\sigma$ &
\end{tabular}
\end{center}
\label{debest}
\end{table}

\newpage

### Resultados globales

Tabla global media comparativa \ref{mglobal} y de desviación típica \ref{dtglobal}

\begin{table}[htbp]
\caption{Resultados globales medios en el problema del APC}
\vspace*{0.3cm}
\begin{adjustwidth}{-0.5in}{-0.5in}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
   &  \multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} &  \multicolumn{4}{c}{\textsc{Texture}}  \\
\textbf{Nombre} & \textbf{Clas} & \textbf{Red}  & \textbf{Agr}   & \textbf{T}    & \textbf{Clas}   & \textbf{Red}  & \textbf{Agr}   & \textbf{T}    & \textbf{Clas}   & \textbf{Red}  & \textbf{Agr}   &  \textbf{T} \\ \hline
1NN       & 77.00 & 0.00 & 38.50 & 0.00 & 87.43 & 0.00 & 43.72 & 0.00 & 92.35 & 0.00 & 46.18 & 0.00 \\
RELIEF    & 79.80 & 33.55 & 56.67 & 0.01 & 86.86 & 3.53 & 45.19 & 0.01 & 95.45 & 42.50 & 68.97 & 0.03 \\
ES        & 75.28 & 81.61 & 78.45 & 110.07 & 85.43 & 90.00 & 87.71 & 71.26 & 89.43 & 83.50 & 86.47 & 224.25 \\
ILS       & 72.14 & 86.45 & 79.29 & 116.36 & 84.29 & 91.77 & 88.03 & 111.60 & 89.80 & 85.50 & 87.65 & 309.72 \\
DE-RAND   & 71.11 & 92.90 & 82.00 & 126.20 & 87.43 & 91.77 & 89.60 & 118.43 & 91.08 & 87.50 & 89.29 & 313.92 \\
DE-BSTCUR & 74.22 & 71.29 & 72.75 & 126.83 & 85.43 & 84.71 & 85.07 & 119.00 & 91.44 & 83.00 & 87.22 & 317.96 \\
DE-BEST
\end{tabular}
\end{center}
\end{adjustwidth}
\label{mglobal}
\end{table}

\begin{table}[htbp]
\caption{Resultados globales desviación típica en el problema del APC}
\vspace*{0.3cm}
\begin{adjustwidth}{-0.5in}{-0.5in}
\begin{center}
\begin{tabular}{ccccc|cccc|cccc}
   &  \multicolumn{4}{c}{\textsc{Colposcopy}} & \multicolumn{4}{c}{\textsc{Ionosphere}} &  \multicolumn{4}{c}{\textsc{Texture}}  \\
\textbf{Nombre} & \textbf{Clas} & \textbf{Red}  & \textbf{Agr}   & \textbf{T}    & \textbf{Clas}   & \textbf{Red}  & \textbf{Agr}   & \textbf{T}    & \textbf{Clas}   & \textbf{Red}  & \textbf{Agr}   &  \textbf{T} \\ \hline
1NN       & 5.13 & 0.00 & 2.56 & 0.00 & 3.43 & 0.00 & 1.72 & 0.00 & 2.26 & 0.00 & 1.13 & 0.00 \\
RELIEF    & 6.00 & 13.24 & 7.00 & 0.00 & 3.66 & 1.18 & 2.15 & 0.0 & 1.90 & 3.54 & 1.80 & 0.00 \\
ES        & 3.40 & 3.48 & 2.41 & 15.94 & & 1.07 & 1.44 & 1.22 & 8.62 & 0.94 & 2.00 & 1.39 & 4.33 \\
ILS       & 2.82 & 2.19 & 2.01 & 0.45 & 4.78 & 1.18 & 2.29 & 0.61 & 3.11 & 1.87 & 1.40 & 2.60 \\
DE-RAND   & 4.68 & 1.65 & 2.49 & 3.87 & 2.46 & 1.18 & 1.70 & 3.49 & 1.75 & 0.00 & 0.88 & 5.59 \\
DE-BSTCUR & 5.52 & 5.04 & 4.37 & 1.01 & 4.55 & 4.33 & 3.96 & 3.96 & 1.91 & 1.36 & 2.45 & 1.26 & 3.18 \\
DE-BEST
\end{tabular}
\end{center}
\end{adjustwidth}
\label{dtglobal}
\end{table}

\newpage

## Análisis de resultados

### Análisis global

### Conclusión


# Bibliografía
La plantilla latex de esta memoria es de Pablo Baeyens Fernández (disponible en [GitHub](https://github.com/mx-psi/metaheuristicas)).
