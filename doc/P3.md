---
title: "\\textbf{Práctica 3.b:} \\ Enfriamento Simulado, Búsqueda Local Reiterada y \\ Evolución Diferencial para el \\ para el Problema del Aprendizaje de Pesos en Características"
author: Miguel Lentisco Ballesteros
subtitle: Metaheurísticas
documentclass: scrbook
classoption: oneside
lang: es
algos: Genéticos, Meméticos
colorlinks: true
bibliography: assets/citas.bib
biblio-style: apalike
link-citations: true
citation-style: assets/estilo.csl
numbersections: true
toc: true
---
## Búsqueda Local (BL)
El uso de BL para distintos algoritmos merece una explicación en este apartado, como algoritmo usado por otros, el armazón general es:

```haskell
busLoc :: StdGen -> Algoritmo
busLoc gen datos = getPesos solRes
  where solRes = evalua hastaQueM (nIter >= 15000 || nVecinos >= 20 * nCaract datos)
    (crearVecino datos) (pesosIniBL datos)) (gen, 0)
```
Donde obviamente cada algoritmo cambiará las condiciones según necesite (ej en vez de 15k, 1k evaluaciones; o sin parada por generación máxima de vecinos), en nuestro caso general hasta 15k iteraciones o cuando el nº de vecinos generados sin cambiar la solución sea 20 * nº características.

La solución inicial, con los índices posibles a mutar (inicialmente todos):
```haskell
pesosIniBL :: Datos -> Estado (Solucion, [Int])
pesosIniBL datos = return (pesosIniRand datos, [0..(nCaract datos - 1)])
```

Y cada iteración creamos un vecino, de manera que si es mejor lo sustituimos y creamos todos los índices posibles a mutar enteros; si no es mejor se devuelve la solución actual sin el índice que ha mutado, y si se ha quedado sin índices que mutar se refrescan todos.
```haskell
-- Creo un nuevo vecino a partir de una solución
crearVecino :: Datos -> (Solucion, [Int]) -> Estado (Solucion, [Int])
crearVecino datos (sol, indices) = do
  let (solNueva, indNuev) = obtenerVecino 0.3 datos indices sol
  let solAct = aumentaVecino sol
  let indNuev' = if solNueva > solAct || null indNuev then [0..(nCaract datos - 1)] else indNuev
  return (max solNueva solAct, indNuev')
```

Finalmente la obtención de un vecino es aplicar el operador de mutación en un índice aleatorio (modificar con un valor normal con desviación típica 0.3 y media 0.0), devolviendo la nueva solución y quitando el índice que se ha modificado de la lista de índices disponibles.
```haskell
obtenerVecino :: Datos -> [Int] -> Solucion -> Estado (Solucion, [Int])
obtenerVecino datos indices sol = do
  let inds = aleatorio (0, length indices - 1)
  let ind = indices !! inds
  let z = rNormal 0.3 0.0
  let pesosN = U.imap (\i x -> if i == ind then restringe $ x + z else x) $ getPesos sol
  return (crearSolucion datos pesosN, delete ind indices)
```

# Algoritmos de búsqueda

## Enfriamento Simulado (ES)
Este algoritmo basado en trayectorias (en concreto permite empeoramientos de la solución actual), es muy similar a la búsqueda local pero añade más diversidad (exploración) a la búsqueda permitiendo tomar vecinos peores. Basado en el recocido del acero, añade una probabilidad de tomar vecinos peores basada en la temperatura (cuanto más alta más probabilidad de aceptar), que empieza siendo muy alta para ir variando en la búsqueda y en cada iteración va enfriandose hasta llegar a la temperatura final, donde se va aceptando menos y menos vecinos (se incrementa la explotación).

De tipos simplemente he hecho un renombre para que sea mas legible, `Temp` es un `Double` y hace referencia a un dato que sea una temperatura.

El esqueleto general sería:
```haskell
eS :: StdGen -> Algoritmo
eS gen datos = getPesos solMej
  where solMej = evaluar (hastaQue (nIter >= 15000 || nExitos == 0)
    (iterEnfriamento datos) (solIniES 0.3 0.3 datos)) (gen, 0)
```

Creamos la sol inicial:
```haskell
-- Crea la solución inicial que consta de: SolAct + + TActual + MejorSol + T0 + Tf
solIniES :: Double -> Temp -> Datos -> Estado (Solucion, Temp, Solucion, Temp, Temp, Int)
solIniES mu phi datos = do
  let solIni = hastaQue (getFit solIni > - log phi * mu * 0.001) (pesosIniRand datos)
  let tempIni = mu * getFit solIni / (- log phi)
  return (solIni, tempIni, solIni, tempIni, 0.001, 1)
```
Considerando que la temperatura inicial es, con $\mu = \phi = 0.3$:

$$T_0 = \frac{\mu f(S_0)}{-ln(\phi)}$$

Creamos varias soluciones iniciales hasta que una de ellas tenga una temperatura inicial válida (que sea mayor que la final, $f(sol) > -0.001 log(\phi)\mu$), y ponemos la temp final a 0.001. La estructura que deuelve sirve para llevar la siguiente información: (solucionActual, temperaturaActual, mejorSolucion, T0, TF, nExitos). T0, TF serán constantes para usarlas al enfriar la temperatura, nExitos marcará el nº de vecinos aceptados en cada iteración (para comprobar si nExitos == 0 y cortar), mejorSolucion será la mejor solución encontrada durante toda la ejecución, y solucionActual y temperaturaActual la solución y temperatura actual en cada iteración.

Cada iteración del bucle será:
```haskell
-- Iteración principal se hace la busqueda en el vecindario y se enfria la temperatura
iterEnfriamento :: Datos -> (Solucion, Temp, Solucion, Temp, Temp, Int) -> Estado (Solucion, Temp, Solucion, Temp, Temp, Int)
iterEnfriamento datos (solAct, tAct, mejSol, t0, tf, _) = do
  let nMaxVec = nCaract datos * 10
  let (solNueva, solMejNueva, nVecExi)
    = hastaQueM (nIter >= 15000 || nVec >= nVecMax || nVecExi >= (nVecMax * 0.1))
    (exploraVecindario datos tAct) (solAct, mejSol, 0, 0)
  let m = redondea (15000 / nMaxVec)
  return (solNueva, enfriaCauchy m tAct t0 tf, solMejNueva, t0, tf, nVecExi)
```
Tomamos el nº máximo de vecinos a generar `nMaxVec` como nº de características por 10, a continuación exploramos el vecindario hasta que lleguemos a las 15k iteraciones, o el nº de vecinos generados llegue al tope, o se hayan aceptado el nº máxito de éxitos; entonces nos devuelve la nueva solución (puede ser la misma que la actual), la mejor solución (puede ser la misma que la actual) y el nº de vecinos aceptados, pasamos toda esta información para la siguiente iteración si procede, enfriando además la temperatura mediante el esquema Cauchy-Mejorado tomando en cuenta que habrá `15000/nMaxVec` iteraciones aproximadamente:

```haskell
enfriaCauchy :: Int -> Temp -> Temp -> Temp -> Temp
enfriaCauchy m t t0 tf = t / (1 + beta * t)
  where beta = (t0 - tf) / (m * t0 * tf)
```

El esquema es:

$$T_{k+1} = \frac{T_k}{1 + \beta T_k}, \; \; \beta = \frac{T_0 - T_F}{M T_0 T_F}$$

Finalmente, la exploración del vecindario se hace de la siguiente manera:

```haskell
exploraVecindario :: Datos -> Temp -> (Solucion, Solucion, Int, Int) -> Estado (Solucion, Solucion, Int, Int)
exploraVecindario datos tAct (solAct, mejSol, nVec, nVecExi) = do
  let solNueva = obtenerVecino 0.3 datos solAct
  let diferencia = getFit solAct - getFit solNueva
  if diferencia == 0
    diferencia = 0.005
  let numR = aleatorio (0.0, 1.0)
  if diferencia' < 0 || numR <= exp (- diferencia / tAct) then
    return (solNueva, max solNueva mejSol, nVec + 1, nVecExi + 1)
  else
    return (solAct, mejSol, nVec + 1, nVecExi)
```

Generamos un nuevo vecino y obtenemos la diferencia de evaluación de la sol actual menos la nueva, si la diferencia es 0 (que suele pasar) le ponemos 0.005 para que no se acepte siempre incluso con temperaturas bajas. Entonces generamos un nº aleatorio y si la diferencia es negativa (el vecino es mejor) o $rand \leq exp(-\frac{-diferencia}{T_{act}})$ entonces aceptamos el vecino como solución actual, comprobamos si es mejor que la mejor solución actual y aumentamos el nº de vecinos aceptados; en caso contrario no hacemos nada. En cualquier caso aumentamos en 1 el nº de vecinos creados.

Finalmente para crear un vecino, aplicamos el mismo operador de mutación de BL:
```haskell
obtenerVecino :: Datos -> Solucion -> Estado Solucion
obtenerVecino sD datos sol = do
  let ind = aleatorio (0, nCaract datos - 1)
  let z = rNormal 0.3 0.0
  let pesosN = imap (\i x -> if i == ind then restringe $ x + z else x) $ getPesos sol
  return crearSolucion datos pesosN
```

## Búsqueda Local Reiterada (ILS)
Este algoritmo basado en trayectorias, subtipo multiarranque, se basa en arrancar muchas veces la búqsueda local de la siguiente manera: tomamos una solución inicial y le aplicamos búsqueda local, después aplicamos un bucle que consiste en mutar la solución actual, aplicarle la búsqueda local y quedarnos con la mejor de la soluciones y volver a repetir.

Como usaremos BL llamamos al esqueleto de BL modificado solo para que pare al hacer 1000 evaluaciones, y sigue el mismo esquema que el explicado en las consideraciones generales.

El esquema general sería:
```haskell
iLS :: StdGen -> Algoritmo
iLS gen datos = getPesos sol
  where sol = evalua (hastaQue (nIter >= 15) (iteracionILS datos) (solIniILS datos)) (gen, 0)
```
Considerando que haremos 15 iteraciones (contando con la solución inicial) a BL tendremos 15000 evaluaciones (igual que en otros algoritmos).

La solución inicial es la misma pero aplicando BL, y llevando la cuenta del nº de iteraciones:
```haskell
solIniILS :: Datos -> Estado (Solucion, Int)
solIniILS datos = return (bL datos (pesosIniRand datos), 1)
```

Cada iteración de ILS será así:
```haskell
iteracionILS :: Datos -> (Solucion, Int) -> Estado (Solucion, Int)
iteracionILS datos (solAct, nIter) = do
  let solMutada = mutarSolILS datos solAct
  let solBL = blILS datos solMutada
  return (max solAct solBL, nIter + 1)
```

Tomamos la sol actual, le aplicamos la operación de mutación, y después BL. Finalmente devolvemos la mejor solución para seguir aplicando el algoritmo y aumentamos en 1 el nº de iteraciones. Como considerabamos el criterio de elección como el mejor no hace falta llevar la cuenta de la mejor solución, en cualquier caso se podría hacer una pequeña modificación si se quisiera cambiar el criterio.

La mutación de la solución:
```haskell
mutarSolILS :: Datos -> Solucion -> Estado Solucion
mutarSolILS datos solAct = do
  let nMut = min 1 $ redondea $ 0.1 * (nCaract datos)
  let pesosMutados = repiteNM nMut (mutarPesos 0.4) (getPesos solAct)
  return crearSolucion datos pesosMutados
```
Esta mutación es parecida a la de siempre pero más agresiva, en este caso usamos desviación tipica 0.4 en vez de 0.3 y además mutamos el 10% de los genes (y ponemos un mínimo de mutación de 1 gen para q mute al menos una vez) usando el operador normal de siempre aplicado `nMut` veces.

## Evolución Diferencial (DE)
Este algoritmo basado en algoritmos genéticos, hace más énfasis en la mutación, que va antes de la recombinación/cruce. El esquema general es generar una población inicial de N cromosomas y hasta que se cumpla la condición de parada seguir el siguiente bucle: para todo individuo de la población se genera un hijo nuevo tomando de base los pesos del padre (individuo i) y de manera que por cada gen del nuevo hijo hay una probabilidad de se aplique el operador de mutación; en cualquier caso cuando se forma el nuevo hijo entero si es mejor que el padre se reemplaza.

Como las dos variantes serán usando un operador de cruce distinto, explicaré en general todo y después veremos las dos fórmulas diferentes usadas en los dos algoritmos. De esta manera el operador de cruce (rand o best-current) está unido al de recombinación (binominal), y después de aplicarse a todos los genes del hijo se aplica el de reemplazo (compara hijo-padre)

Se ha incluido el tipo `EsqMutar` que hace referencia al esquema de mutar que es el siguiente `type EsqMutar = Poblacion -> Int -> Int -> [Int] -> Estado Double`. Tomará la población, los índices i y j (i sobre la población y j sobre el nº)

Empezamos con el esquema general, donde variará segun el esquema de mutación que usemos:
```haskell
dE :: EsqMutar -> StdGen -> Algoritmo
dE esqMut gen datos = getPesos (maximo pobSol)
  where pobSol = evaluar (hastaQue (nIter >= 15000) (iterDE datos esqMut) (crearPobIni 50 datos)) (gen, 0)
```

La población inicial se crea repitiendo n veces creando cromosomas con pesos aleatorios:
```haskell
-- Crea nPob individuos aleatorios
crearPobIni :: Int -> Datos -> Estado Poblacion
crearPobIni nPob datos = repite nPob (crearCromIni datos)
```

Cada iteración del bucle será aplicar la misma operación a cada cromosoma de la población, actualizando la población, y empezando con i = 0:
```haskell
iterDE :: Datos -> EsqMutar -> Poblacion -> Estado Poblacion
iterDE datos esqMutRecom pobActual = repite (sizeOf pobActual) (actualizarPoblacion datos esqMutRecom) (pobActual, 0)
```

Por cada cromosoma generamos unos pesos inicialmente a 9 (da igual) y tomamos 3 índices distintos entre sí y de i que se los pasaremos al esquema de mutación según los necesiten. Al aplicar el bucle interno obtendremos los pesos del nuevo hijo, creando el nuevo cromosoma hijo y finalmente si el hijo es mejor que el padre se sustituye por él en la población (reemplazo) y devolvemos la población actualizada:

```haskell
actualizarPoblacion :: Datos -> EsqMutar -> (Poblacion, Int) -> Estado (Poblacion, Int)
actualizarPoblacion datos esqMut (pob, i) = do
  let vectorIni = replica (nCaract datos) 0
  let indices = tomaIndRand 3 (delete i [0..(sizeOf pob - 1)])
  let hijoNuevo = crearCromosoma datos $ repiteNM (nCaract datos) (mutReemp esqMut pob i indices) (vectorIni, 0)
  if getFit hijoNuevo > getFit pob[i] then pob[i] = hijoNuevo
  return (pob, i + 1)
```

Es muy fácil tomar índices distintos tomando una posición de la lista de índices y repitiendo quitando ese índice de la lista y así:
```haskell
tomaIndRand :: Int -> [Int] -> Estado [Int]
tomaIndRand nInd indices = repite nInd tomaIndice (indices, [])
  where tomaIndice (inds, res) = do
        let k =  (0, sizeOf inds - 1)
        return (delete inds[i] inds, res ++ inds[i])
```

Por último el esquema de mutación/combinación:
```haskell
mutReemp :: EsqMutar -> Poblacion -> Int -> [Int] -> ([Double], Int) -> Estado ([Double], Int)
mutReemp esqMut pob i indices (pesos, j) = do
  let r = aleatorio (0.0, 1.0)
  if r <= (0.5 :: Double) then pesos[j] = esqMut pob i j indices else pesos[j] = pob[i].pesos[k]
  return (pesos, j + 1)
```
Tomamos un nº aleatorio en $[0.0, 1.0]$ y si es menor que CR, que en este caso es 0.5 entonces se el valor del gen j-ésimo valdrá lo que nos dia el operador de mutación; si no se toma lo que valga el gen j-ésimo del padre.

### DE - Rand
El esquema es aleatorio, se toma como mutación 3 padres aleatorios (distintos entre sí y del individuo i-ésimo) y se toma una suma de ellos de una forma (y se restringe al intervalo $[0.0, 1.0]$):
```haskell
mutRand :: EsqMutar
mutRand pob _ j (i1, i2, i3) = return $ restringe $ pob[i1].pesos[j] + 0.5 * (pob[i2].pesos[j] - pob[i3].pesos[j])
```
Obviamente en este caso no se tiene en cuenta al padre i-ésimo y además es una combinación aleatoria pura sin tener en cuenta nada.

### DE - Best Current
El esquema toma en consideración el padre i-ésimo, el mejor individuo de la población y dos padres aleatorios (distintos entre sí y del padre i-ésimo), además se restringe el valor al intervalo $[0.0, 1.0]$:
```haskell
mutCurrentBest :: EsqMutar
mutCurrentBest pob i j i1 i2 = do
  let iMejor = maximum pob `indiceDe` pob
  return $ restringe $ pob[i].pesos[j] + 0.5 * (pob[iMejor].pesos[j]  - pob[i].pesos[j] ) + 0.5 * (pob[i1].pesos[j] - pob[i2].pesos[j])
```

En este caso se tiene en cuenta más quien es el mejor y tira hacia allí añadiendo también un poco de exploración con los padres aleatorios pero teniendo en cuenta la base de la que parte (el padre i-ésimo).
